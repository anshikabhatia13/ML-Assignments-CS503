{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Q1##"
      ],
      "metadata": {
        "id": "Nxe0qm5WuKr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "class SimpleNN:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        np.random.seed(0)\n",
        "        self.W1 = np.random.randn(input_size, hidden_size)\n",
        "        self.b1 = np.zeros((1, hidden_size))\n",
        "        self.W2 = np.random.randn(hidden_size, output_size)\n",
        "        self.b2 = np.zeros((1, output_size))\n",
        "        self.loss_history = []\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def relu_derivative(self, x):\n",
        "        return (x > 0).astype(float)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.z1 = X @ self.W1 + self.b1\n",
        "        self.a1 = self.relu(self.z1)\n",
        "        self.z2 = self.a1 @ self.W2 + self.b2\n",
        "        return self.z2\n",
        "\n",
        "    def backward(self, X, y, output, lr=0.01):\n",
        "        m = y.shape[0]\n",
        "        dz2 = (output - y) * (2/m)\n",
        "        dW2 = self.a1.T @ dz2\n",
        "        db2 = np.sum(dz2, axis=0, keepdims=True)\n",
        "\n",
        "        da1 = dz2 @ self.W2.T\n",
        "        dz1 = da1 * self.relu_derivative(self.z1)\n",
        "        dW1 = X.T @ dz1\n",
        "        db1 = np.sum(dz1, axis=0, keepdims=True)\n",
        "\n",
        "        self.W2 -= lr * dW2\n",
        "        self.b2 -= lr * db2\n",
        "        self.W1 -= lr * dW1\n",
        "        self.b1 -= lr * db1\n",
        "\n",
        "    def train(self, X, y, epochs=1000, lr=0.01):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(X)\n",
        "            loss = np.mean((output - y)**2)\n",
        "            self.loss_history.append(loss)\n",
        "            self.backward(X, y, output, lr)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.forward(X)"
      ],
      "metadata": {
        "id": "RgfYzwH84Kr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_3phase_data(frequency, points):\n",
        "    t = np.linspace(0, 1/frequency, points).reshape(-1, 1)\n",
        "    phase_a = np.sin(2*np.pi*frequency*t)\n",
        "    phase_b = np.sin(2*np.pi*frequency*t + 2*np.pi/3)\n",
        "    phase_c = np.sin(2*np.pi*frequency*t + 4*np.pi/3)\n",
        "    output = np.hstack((phase_a, phase_b, phase_c))\n",
        "    return t, output"
      ],
      "metadata": {
        "id": "fHYA4Kt5u1TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_list = []\n",
        "best_mse = float('inf')\n",
        "worst_mse = -float('inf')\n",
        "best_pred, best_true = None, None\n",
        "worst_pred, worst_true = None, None\n",
        "best_nn, worst_nn = None, None\n",
        "\n",
        "for points_per_cycle in range(1, 11):\n",
        "    print(f\"Training for {points_per_cycle} points per cycle...\")\n",
        "\n",
        "    t, y = generate_3phase_data(50, points_per_cycle)\n",
        "\n",
        "    nn = SimpleNN(input_size=1, hidden_size=20, output_size=3)\n",
        "    print(\"Training the neural network...\")\n",
        "    nn.train(t, y, epochs=3000, lr=0.0001)\n",
        "\n",
        "    preds = nn.predict(t)\n",
        "    mse = np.mean((preds - y)**2)\n",
        "    mse_list.append(mse)\n",
        "\n",
        "    print(f\"MSE for {points_per_cycle} points: {mse}\")\n",
        "\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_pred, best_true = preds, y\n",
        "        best_nn_t5 = nn\n",
        "        print(f\"New best MSE: {best_mse} at {points_per_cycle} points.\")\n",
        "    if mse > worst_mse:\n",
        "        worst_mse = mse\n",
        "        worst_pred, worst_true = preds, y\n",
        "        worst_nn = nn\n",
        "        print(f\"New worst MSE: {worst_mse} at {points_per_cycle} points.\")\n",
        "\n",
        "print(f\"\\nTraining completed.\")\n",
        "print(f\"Best MSE: {best_mse}\")\n",
        "print(f\"Worst MSE: {worst_mse}\")"
      ],
      "metadata": {
        "id": "9o8yEQkO4Rlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Actual Data vs Predicted Data for Worst Case"
      ],
      "metadata": {
        "id": "SvSyYCLeCLyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Best Case: Predicted vs Actual (Lowest MSE)')\n",
        "plt.plot(best_true[:, 0], label='Phase A (True)', color='r')\n",
        "plt.plot(best_pred[:, 0], label='Phase A (Predicted)', color='b')\n",
        "plt.plot(best_true[:, 1], label='Phase B (True)', color='g')\n",
        "plt.plot(best_pred[:, 1], label='Phase B (Predicted)', color='orange')\n",
        "plt.plot(best_true[:, 2], label='Phase C (True)', color='b')\n",
        "plt.plot(best_pred[:, 2], label='Phase C (Predicted)', color='purple')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Worst Case: Predicted vs Actual (Highest MSE)')\n",
        "plt.plot(worst_true[:, 0], label='Phase A (True)', color='r')\n",
        "plt.plot(worst_pred[:, 0], label='Phase A (Predicted)', color='b')\n",
        "plt.plot(worst_true[:, 1], label='Phase B (True)', color='g')\n",
        "plt.plot(worst_pred[:, 1], label='Phase B (Predicted)', color='orange')\n",
        "plt.plot(worst_true[:, 2], label='Phase C (True)', color='b')\n",
        "plt.plot(worst_pred[:, 2], label='Phase C (Predicted)', color='purple')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WwIMjIhnBgLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,11), mse_list, marker='o', color='blue')\n",
        "plt.title('MSE vs Points Per Cycle (50Hz 3-Phase)', fontsize=14)\n",
        "plt.xlabel('Points per Cycle', fontsize=12)\n",
        "plt.ylabel('MSE', fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print('Error Distribution')\n",
        "\n",
        "error_best = (best_true - best_pred).flatten()\n",
        "error_worst = (worst_true - worst_pred).flatten()\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.histplot(error_best, bins=30, color='green', kde=True, label='Best Error', stat='density')\n",
        "sns.histplot(error_worst, bins=30, color='red', kde=True, label='Worst Error', stat='density', alpha=0.6)\n",
        "plt.title('Error Distribution (Best vs Worst Prediction)', fontsize=14)\n",
        "plt.xlabel('Error Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print('Neural Network Weights Visualization')\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12,5))\n",
        "\n",
        "sns.heatmap(best_nn_t5.W1, cmap='coolwarm', ax=axs[0])\n",
        "axs[0].set_title('Best Model: W1 Weights')\n",
        "\n",
        "sns.heatmap(best_nn_t5.W2, cmap='coolwarm', ax=axs[1])\n",
        "axs[1].set_title('Best Model: W2 Weights')\n",
        "\n",
        "plt.suptitle('Neural Network Weights Visualization', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F0choeSt4X6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(nn.loss_history, color='purple')\n",
        "plt.title('Loss (MSE) During Training', fontsize=14)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print('Hidden Layer Activations')\n",
        "activations = nn.relu(t @ nn.W1 + nn.b1)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.imshow(activations, aspect='auto', cmap='viridis', interpolation='nearest')\n",
        "plt.colorbar(label='Activation Strength')\n",
        "plt.title('Hidden Layer Activations ', fontsize=14)\n",
        "plt.xlabel('Neuron Index')\n",
        "plt.ylabel('Sample Index')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ymyLXeN_vibX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWM9hhkb3Ity"
      },
      "outputs": [],
      "source": [
        "class SimpleNNVisualizer:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        np.random.seed(0)\n",
        "        self.W1 = np.random.randn(input_size, hidden_size)\n",
        "        self.b1 = np.zeros((1, hidden_size))\n",
        "        self.W2 = np.random.randn(hidden_size, output_size)\n",
        "        self.b2 = np.zeros((1, output_size))\n",
        "\n",
        "        self.activations = []\n",
        "        self.gradients = []\n",
        "        self.weights_history = []\n",
        "        self.loss_history = []\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def relu_derivative(self, x):\n",
        "        return (x > 0).astype(float)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.z1 = X @ self.W1 + self.b1\n",
        "        self.a1 = self.relu(self.z1)\n",
        "        self.z2 = self.a1 @ self.W2 + self.b2\n",
        "        return self.z2\n",
        "\n",
        "    def backward(self, X, y, output, lr=0.01):\n",
        "        m = y.shape[0]\n",
        "        dz2 = (output - y) * (2/m)\n",
        "        dW2 = self.a1.T @ dz2\n",
        "        db2 = np.sum(dz2, axis=0, keepdims=True)\n",
        "\n",
        "        da1 = dz2 @ self.W2.T\n",
        "        dz1 = da1 * self.relu_derivative(self.z1)\n",
        "        dW1 = X.T @ dz1\n",
        "        db1 = np.sum(dz1, axis=0, keepdims=True)\n",
        "\n",
        "        # Gradients\n",
        "        self.gradients.append({\n",
        "            'dz2': dz2,\n",
        "            'dW2': dW2,\n",
        "            'dz1': dz1,\n",
        "            'dW1': dW1,\n",
        "        })\n",
        "\n",
        "        self.W2 -= lr * dW2\n",
        "        self.b2 -= lr * db2\n",
        "        self.W1 -= lr * dW1\n",
        "        self.b1 -= lr * db1\n",
        "\n",
        "    def train(self, X, y, epochs=1000, lr=0.01, snapshot_interval=100):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(X)\n",
        "            loss = np.mean((output - y) ** 2)\n",
        "            self.loss_history.append(loss)\n",
        "\n",
        "            if epoch % snapshot_interval == 0:\n",
        "                self.activations.append((self.z1.copy(), self.a1.copy(), self.z2.copy()))\n",
        "                self.weights_history.append((self.W1.copy(), self.W2.copy()))\n",
        "\n",
        "            self.backward(X, y, output, lr)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.forward(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing Working of the Simple Neural Network"
      ],
      "metadata": {
        "id": "OHXhkSjrDkc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn = SimpleNNVisualizer(input_size=1, hidden_size=10, output_size=3)\n",
        "nn.train(t, y, epochs=3000, lr=0.01, snapshot_interval=100)\n",
        "\n",
        "z1, a1, z2 = nn.activations[-1]\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(2,1,1)\n",
        "plt.imshow(z1, aspect='auto', cmap='plasma')\n",
        "plt.colorbar()\n",
        "plt.title('Hidden Pre-Activation z1 (before ReLU)')\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.imshow(a1, aspect='auto', cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.title('Hidden Post-Activation a1 (after ReLU)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uigBPZmG4zlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad = nn.gradients[-1]\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(grad['dW1'], aspect='auto', cmap='coolwarm')\n",
        "plt.colorbar()\n",
        "plt.title('Gradient dW1 (Input -> Hidden)')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(grad['dW2'], aspect='auto', cmap='coolwarm')\n",
        "plt.colorbar()\n",
        "plt.title('Gradient dW2 (Hidden -> Output)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iJ8KsYAl41lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1_start, W2_start = nn.weights_history[0]\n",
        "W1_end, W2_end = nn.weights_history[-1]\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(W1_start, cmap='bwr')\n",
        "plt.title('W1 at Start')\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(W1_end, cmap='bwr')\n",
        "plt.title('W1 at End')\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(W2_start, cmap='bwr')\n",
        "plt.title('W2 at Start')\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.imshow(W2_end, cmap='bwr')\n",
        "plt.title('W2 at End')\n",
        "plt.colorbar()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "82Z2rFeP422r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2##"
      ],
      "metadata": {
        "id": "0XU26o1xuHb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sine_wave_data(frequency, points):\n",
        "    t = np.linspace(0, 1/frequency, points).reshape(-1, 1)\n",
        "    y = np.sin(2 * np.pi * frequency * t)\n",
        "    return t, y"
      ],
      "metadata": {
        "id": "h2j_l3Ia0OSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_list = []\n",
        "loss_history_all_models = {}\n",
        "\n",
        "t, y = generate_sine_wave_data(130, 1000)\n",
        "\n",
        "for hidden_neurons in range(1, 201, 10):\n",
        "    print(f\"Training model with {hidden_neurons} hidden neurons...\")\n",
        "\n",
        "    nn = SimpleNN(input_size=1, hidden_size=hidden_neurons, output_size=1)\n",
        "    nn.train(t, y, epochs=3000, lr=0.0001)\n",
        "    preds = nn.predict(t)\n",
        "\n",
        "    mse = np.mean((preds - y)**2)\n",
        "    mse_list.append(mse)\n",
        "    loss_history_all_models[hidden_neurons] = nn.loss_history\n",
        "\n",
        "    print(f\"MSE for {hidden_neurons} hidden neurons: {mse}\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(t, y, label=\"True Sine Wave (130Hz)\")\n",
        "plt.title('True 130 Hz Single-Phase Sine Wave')\n",
        "plt.xlabel('Time (t)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for hidden_neurons, loss_history in loss_history_all_models.items():\n",
        "    plt.plot(range(0, len(loss_history)*100, 100), loss_history, label=f'{hidden_neurons} Neurons')\n",
        "plt.title('Training Loss vs. Epochs for Different Hidden Layer Sizes')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, 201, 10), mse_list, marker='o')\n",
        "plt.title('MSE vs Number of Neurons in Hidden Layer (130Hz Sine Wave)')\n",
        "plt.xlabel('Number of Neurons in Hidden Layer')\n",
        "plt.ylabel('MSE (Error)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "best_mse = min(mse_list)\n",
        "best_neurons = (mse_list.index(best_mse) + 1) * 10\n",
        "print(f\"Best model has {best_neurons} neurons with MSE: {best_mse}\")\n",
        "\n",
        "best_nn = SimpleNN(input_size=1, hidden_size=best_neurons, output_size=1)\n",
        "best_nn.train(t, y, epochs=3000, lr=0.0001)\n",
        "best_pred = best_nn.predict(t)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(t, y, label=\"True Sine Wave\")\n",
        "plt.plot(t, best_pred, label=\"Best Model Prediction\", linestyle='--')\n",
        "plt.title(f'Best Model Prediction vs True Output ({best_neurons} Neurons)')\n",
        "plt.xlabel('Time (t)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "worst_mse_index = mse_list.index(max(mse_list))\n",
        "worst_neurons = (worst_mse_index + 1) * 10\n",
        "worst_nn = SimpleNN(input_size=1, hidden_size=worst_neurons, output_size=1)\n",
        "worst_nn.train(t, y, epochs=3000, lr=0.0001)\n",
        "worst_pred = worst_nn.predict(t)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(t, y, label=\"True Sine Wave\")\n",
        "plt.plot(t, worst_pred, label=\"Worst Model Prediction\", linestyle='--')\n",
        "plt.title(f'Worst Model Prediction vs True Output ({worst_neurons} Neurons)')\n",
        "plt.xlabel('Time (t)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "42qIEU6R0Rcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3##"
      ],
      "metadata": {
        "id": "IJLQsDfFERIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_sine_wave_data(frequency, points):\n",
        "    t = np.linspace(0, 1/frequency, points).reshape(-1, 1)\n",
        "    y = np.sin(2 * np.pi * frequency * t)\n",
        "    return t, y\n",
        "\n",
        "t_130, y_130 = generate_sine_wave_data(130, 250)\n",
        "\n",
        "hidden_sizes = [ 10, 20,30]\n",
        "learning_rates = [1e-2, 1e-3, 1e-4]\n",
        "epoch_list = [1000,2000, 3000,4000]\n",
        "\n",
        "best_new_mse = float('inf')\n",
        "best_new_config = None\n",
        "best_new_model = None\n",
        "\n",
        "new_model_results = []\n",
        "\n",
        "print(\"\\n--- Tuning New Model ---\")\n",
        "\n",
        "for hidden_size in hidden_sizes:\n",
        "    for lr in learning_rates:\n",
        "        for epochs in epoch_list:\n",
        "            model = SimpleNN(input_size=1, hidden_size=hidden_size, output_size=3)\n",
        "            model.train(t_130, y_130, epochs=epochs, lr=lr)\n",
        "            preds = model.predict(t_130)\n",
        "            mse = np.mean((preds - y_130)**2)\n",
        "\n",
        "            print(f\"Hidden Size: {hidden_size}, LR: {lr}, Epochs: {epochs} -> MSE: {mse:.6f}\")\n",
        "\n",
        "            new_model_results.append((hidden_size, lr, epochs, mse))\n",
        "\n",
        "            if mse < best_new_mse:\n",
        "                best_new_mse = mse\n",
        "                best_new_config = (hidden_size, lr, epochs)\n",
        "                best_new_model = model\n",
        "\n",
        "print(f\"\\nBest New Model Config: Hidden Size={best_new_config[0]}, LR={best_new_config[1]}, Epochs={best_new_config[2]}, MSE={best_new_mse:.6f}\")"
      ],
      "metadata": {
        "id": "Wyjf3m3G0fgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "pretrained_nn=best_nn_t5\n",
        "best_pretrain_mse = float('inf')\n",
        "best_pretrain_config = None\n",
        "best_pretrained_model = None\n",
        "\n",
        "pretrain_model_results = []\n",
        "\n",
        "print(\"\\n--- Tuning Pretrained Model ---\")\n",
        "\n",
        "for hidden_size in hidden_sizes:\n",
        "    for lr in learning_rates:\n",
        "        for epochs in epoch_list:\n",
        "            model = copy.deepcopy(pretrained_nn)\n",
        "            model.train(t_130, y_130, epochs=epochs, lr=lr)\n",
        "            preds = model.predict(t_130)\n",
        "            mse = np.mean((preds - y_130)**2)\n",
        "\n",
        "            print(f\"Hidden Size: {hidden_size}, LR: {lr}, Epochs: {epochs} -> MSE: {mse:.6f}\")\n",
        "\n",
        "            pretrain_model_results.append((hidden_size, lr, epochs, mse))\n",
        "\n",
        "            if mse < best_pretrain_mse:\n",
        "                best_pretrain_mse = mse\n",
        "                best_pretrain_config = (hidden_size, lr, epochs)\n",
        "                best_pretrained_model = model\n",
        "\n",
        "print(f\"\\nBest Fine-tuned Pretrained Model Config: Hidden Size={best_pretrain_config[0]}, LR={best_pretrain_config[1]}, Epochs={best_pretrain_config[2]}, MSE={best_pretrain_mse:.6f}\")\n"
      ],
      "metadata": {
        "id": "Q_JhUCFU4zWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model_results = np.array(new_model_results)\n",
        "pretrain_model_results = np.array(pretrain_model_results)\n",
        "\n",
        "plt.figure(figsize=(20,18))\n",
        "for lr in np.unique(new_model_results[:,1]):\n",
        "    for epochs in np.unique(new_model_results[:,2]):\n",
        "        mask = (new_model_results[:,1] == lr) & (new_model_results[:,2] == epochs)\n",
        "        plt.plot(new_model_results[mask][:,0], new_model_results[mask][:,3], marker='o', label=f\"LR={lr}, Epochs={epochs}\")\n",
        "plt.title('New Model: Hidden Size vs MSE')\n",
        "plt.xlabel('Hidden Size')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "print('\\n')\n",
        "plt.figure(figsize=(20,18))\n",
        "for lr in np.unique(pretrain_model_results[:,1]):\n",
        "    for epochs in np.unique(pretrain_model_results[:,2]):\n",
        "        mask = (pretrain_model_results[:,1] == lr) & (pretrain_model_results[:,2] == epochs)\n",
        "        plt.plot(pretrain_model_results[mask][:,0], pretrain_model_results[mask][:,3], marker='o', label=f\"LR={lr}, Epochs={epochs}\")\n",
        "plt.title('Pretrained Model: Hidden Size vs MSE')\n",
        "plt.xlabel('Hidden Size')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6JKT-42x7SPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_preds = best_new_model.predict(t_130)\n",
        "pretrain_preds = best_pretrained_model.predict(t_130)"
      ],
      "metadata": {
        "id": "5bKIu3LR6KnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(t_130, y_130, label=\"True 130Hz Sine\")\n",
        "plt.plot(t_130, new_preds, '--', label=\"Best New Model Prediction\")\n",
        "plt.title(f'Best New Model (MSE: {best_new_mse:.6f})')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "print('\\n')\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(t_130, y_130, label=\"True 130Hz Sine\")\n",
        "plt.plot(t_130, pretrain_preds, '--', label=\"Best Fine-Tuned Pretrained Model Prediction\")\n",
        "plt.title(f'Best Fine-Tuned Pretrained Model (MSE: {best_pretrain_mse:.6f})')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(\"\\n--- Final Comparison ---\")\n",
        "print(f\"Best New Model MSE: {best_new_mse:.6f}\")\n",
        "print(f\"Best Fine-tuned Pretrained Model MSE: {best_pretrain_mse:.6f}\")\n",
        "\n",
        "if best_pretrain_mse < best_new_mse:\n",
        "    print(\"Fine-tuned pretrained model performs BETTER than training new model from scratch!\")\n",
        "else:\n",
        "    print(\"Training new model from scratch performs BETTER than fine-tuning pretrained model!\")"
      ],
      "metadata": {
        "id": "arf6IrBY0h73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4##"
      ],
      "metadata": {
        "id": "JaSlkpMu-g3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_waveform(sample_points=100, freq_range=(1,20)):\n",
        "    freq = np.random.uniform(*freq_range)\n",
        "    t = np.linspace(0, 1, sample_points)\n",
        "    y = np.sin(2 * np.pi * freq * t)\n",
        "    return t, y, freq\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "n_samples = 5000\n",
        "sample_points = 100\n",
        "\n",
        "for _ in range(n_samples):\n",
        "    _, waveform, freq = generate_waveform(sample_points=sample_points)\n",
        "    X.append(waveform)\n",
        "    y.append(freq)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ],
      "metadata": {
        "id": "cWo6LaHL0z8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_val = y_val.reshape(-1,1)\n"
      ],
      "metadata": {
        "id": "u3Ysk-Cx02Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_sizes = [8, 16, 32, 64]\n",
        "learning_rates = [1e-2, 1e-3, 1e-4]\n",
        "epoch_list = [1000, 2000, 3000]\n",
        "\n",
        "results = []\n",
        "\n",
        "best_mse = float('inf')\n",
        "best_config = None\n",
        "best_model = None\n",
        "\n",
        "for hidden_size in hidden_sizes:\n",
        "    for lr in learning_rates:\n",
        "        for epochs in epoch_list:\n",
        "            print(f\"Training with Hidden Size={hidden_size}, LR={lr}, Epochs={epochs}\")\n",
        "            model = SimpleNN(input_size=100, hidden_size=hidden_size, output_size=1)\n",
        "            model.train(X_train, y_train, epochs=epochs, lr=lr)\n",
        "            preds = model.predict(X_train)\n",
        "            mse = np.mean((preds - y_train)**2)\n",
        "\n",
        "            print(f\"-> MSE: {mse:.6f}\\n\")\n",
        "\n",
        "            results.append((hidden_size, lr, epochs, mse))\n",
        "\n",
        "            if mse < best_mse:\n",
        "                best_mse = mse\n",
        "                best_config = (hidden_size, lr, epochs)\n",
        "                best_model = model\n",
        "\n",
        "print(f\"\\nBest Config: Hidden Size={best_config[0]}, LR={best_config[1]}, Epochs={best_config[2]}, Best MSE={best_mse:.6f}\")"
      ],
      "metadata": {
        "id": "DEioN6XW03Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results, columns=[\"hidden_size\", \"lr\", \"epochs\", \"mse\"])\n",
        "best_epoch = 3000\n",
        "filtered_df = results_df[results_df['epochs'] == best_epoch]\n",
        "\n",
        "pivot_table = filtered_df.pivot(index=\"hidden_size\", columns=\"lr\", values=\"mse\")\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap=\"coolwarm\")\n",
        "plt.title(f\"Validation MSE Heatmap (Epochs={best_epoch})\")\n",
        "plt.ylabel(\"Hidden Size\")\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NEDO5gUW_hVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr = best_config[1]\n",
        "\n",
        "filtered_df2 = results_df[(results_df['lr'] == best_lr) & (results_df['epochs'] == best_epoch)]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(filtered_df2['hidden_size'], filtered_df2['mse'], marker='o')\n",
        "plt.title(f\"Hidden Size vs MSE (LR={best_lr}, Epochs={best_epoch})\")\n",
        "plt.xlabel(\"Hidden Layer Size\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MxLpABsZ_jff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=best_model"
      ],
      "metadata": {
        "id": "xsvJ-6HO_k_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.loss_history\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vjGV3MI797F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_val)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(y_val, y_pred, alpha=0.5)\n",
        "plt.plot([1,20],[1,20],'r--')\n",
        "plt.xlabel(\"True Frequency (Hz)\")\n",
        "plt.ylabel(\"Predicted Frequency (Hz)\")\n",
        "plt.title(\"Predicted vs True Frequency (Validation Set)\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "val_mse = np.mean((y_pred - y_val)**2)\n",
        "print(f\"Validation MSE: {val_mse:.6f}\")\n"
      ],
      "metadata": {
        "id": "0OwEJo_i04q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_dominant_frequency_fft(signal, sample_rate=100):\n",
        "    n = len(signal)\n",
        "    freqs = np.fft.rfftfreq(n, d=1/sample_rate)\n",
        "    fft_vals = np.abs(np.fft.rfft(signal))\n",
        "    dominant_freq = freqs[np.argmax(fft_vals)]\n",
        "    return dominant_freq\n"
      ],
      "metadata": {
        "id": "6iI9-Y5P-xFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_points = 100\n",
        "sample_rate = sample_points\n",
        "n_tests = 20\n",
        "errors_nn = []\n",
        "errors_fft = []\n",
        "\n",
        "for _ in range(n_tests):\n",
        "    t, waveform, true_freq = generate_waveform(sample_points=sample_points)\n",
        "    waveform_input = waveform.reshape(1, -1)\n",
        "    nn_pred = model.predict(waveform_input).flatten()[0]\n",
        "\n",
        "    fft_pred = find_dominant_frequency_fft(waveform, sample_rate)\n",
        "\n",
        "    error_nn = abs(nn_pred - true_freq)\n",
        "    error_fft = abs(fft_pred - true_freq)\n",
        "\n",
        "    errors_nn.append(error_nn)\n",
        "    errors_fft.append(error_fft)\n",
        "\n",
        "    print(f\"True Frequency: {true_freq:.2f} Hz | NN Pred: {nn_pred:.2f} Hz | FFT Pred: {fft_pred:.2f} Hz\")\n",
        "\n",
        "print(f\"\\nAverage Absolute Error (NN): {np.mean(errors_nn):.4f} Hz\")\n",
        "print(f\"Average Absolute Error (FFT): {np.mean(errors_fft):.4f} Hz\")\n"
      ],
      "metadata": {
        "id": "oAq6ff8M-y8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(errors_nn, label='NN Error', marker='o')\n",
        "plt.plot(errors_fft, label='FFT Error', marker='x')\n",
        "plt.xlabel('Test Sample Index')\n",
        "plt.ylabel('Absolute Frequency Error (Hz)')\n",
        "plt.title('NN vs FFT Frequency Estimation Error')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0fUf24GC-0Cp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}